
#+PROPERTY: header-args:jupyter-python :kernel PROMICE_dev :session PROMICE-README :exports both
#+PROPERTY: header-args:bash :exports both

* Table of contents                               :toc_3:noexport:
- [[#example-code][Example code]]
  - [[#command-line][Command line]]
  - [[#command-line-parallelized][Command line: parallelized]]
  - [[#python][Python]]
- [[#introduction][Introduction]]
  - [[#overview][Overview]]
- [[#level-0][Level 0]]
  - [[#l0-files][L0 files]]
    - [[#additional-files][Additional files]]
- [[#compare-python--idl][Compare Python & IDL]]
  - [[#load-both-to-dfs-10-min][Load both to dfs (10 min)]]
  - [[#compare-2][Compare 2]]

* Example code

** Command line

#+BEGIN_SRC bash :results output :exports both
python promiceAWS.py --config_file=./test_data/L0/config/QAS_L.toml --data_dir=./test_data
ls ./test_data/L3/QAS_L
#+END_SRC

#+RESULTS:
: QAS_L_day.csv
: QAS_L_day.nc
: QAS_L_hour.csv
: QAS_L_hour.nc

** Command line: parallelized

#+BEGIN_SRC bash :results output :exports both
parallel --bar "python promiceAWS.py --config_file={1} --data_dir=./test_data" ::: $(ls ./test_data/L0/config/*)
ls ./test_data/L3/*/
#+END_SRC

#+RESULTS:
#+begin_example
./test_data/L3/QAS_L/:
QAS_L_day.csv
QAS_L_day.nc
QAS_L_hour.csv
QAS_L_hour.nc

./test_data/L3/QAS_M/:
QAS_M_day.csv
QAS_M_day.nc
QAS_M_hour.csv
QAS_M_hour.nc

./test_data/L3/QAS_U/:
QAS_U_day.csv
QAS_U_day.nc
QAS_U_hour.csv
QAS_U_hour.nc
#+end_example

** Python

#+BEGIN_SRC python :results output
from promiceAWS import promiceAWS
pAWS = promiceAWS(config_file='./test_data/L0/config/QAS_L.toml', data_dir='./test_data')
pAWS.process()
pAWS.write(data_dir='./test_data') # Saves L3 data 4x: Daily and hourly in both CSV and NetCDF format
#+END_SRC

#+RESULTS:

* Introduction

Code used to process the PROMICE AWS data from Level 0 through Level 3 (end-user product).

Currently, this code focuses on the *transmitted* data.

We use the following processing levels, described textually and graphically.

** Overview
+ L0: Raw data in CSV file format in one of three formats:
  + [ ] =raw= (see below)
  + [ ] =STM= (Slim Table Memory; see below)
  + [X] =TX= (transmitted; see below)
  + Manually split so no file includes changed sensors, changed calibration parameters, etc.
  + [X] Manually created paired header files based on [[./example.toml]] or in the =data/L0/config= folder.
+ L1:
  + [X] Engineering units (e.g. current or volts) converted to physical units (e.g. temperature or wind speed)
+ L1A:
  + [ ] Invalid / bad / suspicious data flagged
  + [X] Files merged to one time series per station
+ L2:
  + [X] Calibration using secondary sources (e.g. radiometric correction requires input of tilt sensor)
+ L3:
  + [X] Derived products (e.g. SHF and LHF)
  + [ ] Merged, patched, and filled (raw > STM > TX) to one product

#+begin_src ditaa :file ./fig/levels.png :exports results

                    +----------------+
	            |{d}             |                         Legend
                    | Digital counts |                         +---------------+
                    |                |                         |input          |
		    | CR-1000 logger |                         +---------------+
	            |                |
	            +-------+--------+                         +---------------+   +=----+
	                    |				       |{io}process    +--=+ Note|
	                    v				       +---------------+   +-----+
                    +----------------+
	            |{io}            |                         +---------------+
                    |  Manual Carry  |      		       |{d}Files       |
                    |      or        |      		       +---------------+
		    |   Satellite    |
	            |                |			
	            +-------+--------+
	                    |                               +------------------+
	                    v         			  +-+Column names      |
                    +----------------+   +------------+   | +------------------+
	            |{d}             |   |{d}         |<--+
                    |  raw, STM, TX  |   |   TOML     |	    +------------------+
     Level 0 (L0)   |                |   |  config    |<----+ ?                |
		    | GEUS text files|	 |   file     |	    +------------------+
	            |                |	 |            |<--+
	            +-------+--------+   +--+---------+   | +-----------------------------------+
	                    |               |	          +-+ Instrument calibration parameters |
                            |               |		    |      (recorded, not applied)      |
			    |  	+-----------+               +-----------------------------------+
	                    |	|			    
	                    v   v			    
	            +-----------------+           	            
	            |{io}             |                         
	            |  Engineering to |   	   	        
	            |  physical units |                         
	            |                 |   
                    +-------+---------+   
		            |      	  
	                    v             
                    +-----------------+   
		    |{d}              |   
    Level 1 (L1)    |Measured physical|   
		    |    properties   |
		    |                 |
		    +-------+---------+	  
                            |		  
                            v		  
                    +-----------------+
                    |{io}             |
                    | -Flag bad data- |
                    |   Merge files   |
                    |                 |
                    +-------+---------+
                            |           
                            v          
                   +-------------------+
                   |{d}                |
    Level 1A (L1A) |Time series per AWS|
                   |  Initial data QC  |
		   |                   |
                   +-------+-----------+
                           |
                           v
                    +-----------------+
                    |{io}             |       +=------------------------------------------+ 
                    | Cross-sensor    |------=+e.g. ice at 1 m depth via interpolation, or| 
                    |  corrections    |       |radiation adjusting for platform rotation  |
                    |                 |       +-------------------------------------------+ 
                    +-------+---------+       
                            |          
                            v          
                   +-------------------+
                   |{d}                |
     Level 2 (L2)  |  Derived internal |
                   |      values       |
	           |                   |
                   +-------+-----------+
                           |
                           v
                    +-----------------+
                    |{io}             |
                    |     Derive      |       +=-----------------------+
                    |    external     |------=+e.g. sensible heat flux,|
                    |   properties    |       |latent heat flux        |
                    |                 |       +------------------------+
                    +-------+---------+
                            |          
                            v          
                   +-------------------+
                   |{d}                |
     Level 3 (L3)  |  Derived external |
                   |      values       |
		   |                   |
                   +-------------------+


#+END_SRC
		    
#+RESULTS:
[[file:./fig/levels.png]]

* Level 0

Level 0 is generated from one of three methods:
+ [ ] Copied from CF card in the field
+ [ ] Downloaded from logger box in the field
+ [X] Transmitted via satellite and decoded by https://github.com/GEUS-Glaciology-and-Climate/awsrx

#+begin_src plantuml :file ./fig/L00_to_L0.png :exports results
@startuml

' plantuml activity diagram (beta)

component Sensor_1
component Sensor_n

frame CR_Logger {
  database DB_logger [
  <b>Database</b>
  10 minute sampling
  ----
  var0, var1, ..., varn
] 
}

Sensor_1 --> CR_Logger
Sensor_n --> CR_Logger

node GEUS_(Level_0) {
  file Raw [
  <b>raw</b>
  10 min sampling
  ]

  file SlimTableMem [
  <b>SlimTableMem</b>
  Hourly average from
  10 min sampling
  ]

  file TX [
  <b>TX</b>
  V3:
    DOY 100 to 300: hourly average
    DOY 300 to 100: daily average
  V4:
    hourly average all days
  ]
}

' DB -> hand carry -> raw
actor :Site visit: as visitor
DB_logger --> visitor : Field\ndownload
visitor --> Raw : Hand\ncarry
visitor --> SlimTableMem : Hand\ncarry

' DB -> satellite -> Transmitted
cloud Satellite
file Email
queue awsrx
note right
   https://github.com/GEUS-PROMICE/awsrx
end note

DB_logger -[dashed]-> Satellite : Data subsampled and\npossible transmission loss
Satellite -[dashed]-> Email
Email --> awsrx
awsrx --> TX

@enduml
#+end_src

#+RESULTS:
[[file:./fig/L00_to_L0.png]]

** L0 files

+ =raw= : All 10-minute data stored on the CF-card (external module on CR logger)
+ =SlimTableMem= : Hourly averaged 10-min data stored in the internal logger memory
+ =transmitted= : Transmitted via satellite. Only a subset of data is transmitted, and only hourly or daily average depending on station and day of year.

Level 0 files are stored in the =data/L0/<S>/= folder, where =<S>= is the station name. File names can be anything are are processed as per the =TOML= config files, but ideally they should encode the station, end-of-year of download, a version number if there are multiple files for a given year, and the format. Best practices would use the following conventions:  

+ Generic :: =data/<L>/<S>/<S>_<Y>[.<n>]_<F>.txt=
+ Example :: =data/L0/QAS_L/QAS_L_2021_raw_transmitted.txt=

Where 

+ =<L>= is the processing level
  + =<L>= must be one of the following: [L0, L1, L1A, L2, L3]
+ =<S>= is a station ID
  + =<S>= must be one of the following strings: [CEN, EGP, KAN_B, KAN_L, KAN_M, KAN_U, KPC_L, KPC_U, MIT, NUK_K, NUK_L, NUK_N, NUK_U, QAS_A, QAS_L, QAS_M, QAS_U, SCO_L, SCO_U, TAS_A, TAS_L, TAS_U, THU_L, THU_U, UPE_L, UPE_U]
+ =<Y>= is a four-digit year with a value greater than =2008=
  + =<Y>= should represent the year at the last timestamp in the file
  + Optionally, =.<n>= is a version number if multiple files from the same year are present
+ =<F>= is the format, one of =raw=, =TX=, or =STM=

Each L0 file that will be processed must have an entry in the TOML-formatted configuration file. The config file can be located anywhere, and the processing script receives the config file and the location of the L0 data. An [[./example.toml][example (template) L0 config file]] is:

#+BEGIN_SRC bash :results verbatim :exports results
cat example.toml
#+END_SRC

#+RESULTS:
#+begin_example
station_id         = "EGP"
latitude           = 75.62
longitude          = -35.98
nodata             = ['-999', 'NAN'] # if one is a string, all must be strings
dsr_eng_coef       = 12.71  # from manufacturer to convert from eng units (1E-5 V) to  physical units (W m-2)
usr_eng_coef       = 12.71
dlr_eng_coef       = 12.71
ulr_eng_coef       = 12.71

columns = ["time", "rec", "min_y",
	"p", "t_1", "t_2", "rh", "wspd", "wdir", "wd_std",
	"dsr", "usr", "dlr", "ulr", "t_rad",
	"z_boom", "z_boom_q", "z_stake", "z_stake_q", "z_pt",
	"t_i_1", "t_i_2", "t_i_3", "t_i_4", "t_i_5", "t_i_6", "t_i_7", "t_i_8",
	"tilt_x", "tilt_y",
	"gps_time", "gps_lat", "gps_lon", "gps_alt", "gps_geoid", "SKIP_34", "SKIP_35", "gps_numsat", "gps_hdop",
	"t_log", "fan_dc", "SKIP_40", "batt_v_ss", "batt_v"]

# Parameters applied to all files are above.
# Define files for processing and
# override file-specific parameters below.

["EGP_2016_raw.txt"]
format    = "raw"
skiprows  = 3
hygroclip_t_offset = 0      # degrees C

["EGP_2019_raw_transmitted.txt"]
hygroclip_t_offset = 0
skiprows = 0
format   = "TX"
columns = ["time", "rec",
	"p", "t_1", "t_2", "rh", "wspd", "wdir",
	"dsr", "usr", "dlr", "ulr", "t_rad",
	"z_boom", "z_stake", "z_pt",
	"t_i_1", "t_i_2", "t_i_3", "t_i_4", "t_i_5", "t_i_6", "t_i_7", "t_i_8",
	"tilt_x", "tilt_y",
	"gps_time", "gps_lat", "gps_lon", "gps_alt", "gps_hdop",
	"fan_dc", "batt_v"]
#+end_example

The TOML config file has the following expectations and behaviors:
+ Properties can be defined at the top level or under a section
+ Each file that will be processed gets its own section
+ Properties at the top level are copied to each section (assumed to apply to all files)
+ Top-level properties are overridden by file-level properties if they exist in both locations

In the example above,
+ The =station_id=, =latitude=, etc. properties are the same in both files (=EGP_2016_raw.txt= and =EGP_2019_raw_transmitted.txt=) and so they are defined once at the top of the file. They could have been defined in each of the sections similar to =hygroclip_t_offset=.
+ The =format= and =skiprows= properties are different in each section and defined in each section
+ The top-level defined =columns= is applied only to =EGP_2016_raw.txt= because it is defined differently in the =EGP_2019_raw_transmitted.txt= section.

*** Additional files

Any files that do not have an associated section in the config file will be ignored. However, for cleanliness, L0 files that will not be processed should be placed in an =L0/<S>/archive= subfolder.

Any changes made to L0 files should be documented in the [[./L0/README.org]]. *Manual changes to these files should only be done when necessary*. An example of a manual change might be:

+ Raw file contains multiple years of data, including replacing sensors that have different calibration units. The file should be split so that each file only contains one version of each sensor (assuming different versions need different metadata).

* Compare Python & IDL
:PROPERTIES:
:header-args:jupyter-python+: :session compare
:END:
** Load both to dfs (10 min)

#+BEGIN_SRC jupyter-python :tangle compare.py
import numpy as np
import pandas as pd
import xarray as xr

station='QAS_L'
# if 'idl' in locals(): del(idl)
if 'df' in locals(): del(df)

def mydf(y,m,d,h):
    return pd.to_datetime(f'{int(y)}-{int(m)}-{int(d)}:{int(h)}', format='%Y-%m-%d:%H')

def mydf2(y,mo,d,h,mi):
    return pd.to_datetime(f'{int(y)}-{int(mo)}-{int(d)}:{int(h)}:{int(mi)}', format='%Y-%m-%d:%H:%M')

if 'idl' not in locals():
    ## INST
    #idl = pd.read_csv("./IDL/out/"+station+"_inst_v03.txt",
    idl = pd.read_csv("/home/kdm/data.me/PROMICE/inst/"+station+"_inst_v03.txt",
                      delimiter="\s+",
                      parse_dates={'time':[0,1,2,3,4]},
                      infer_datetime_format=True,
                      date_parser=mydf2,
                      index_col=0)
    
    ## HOUR
    # idl = pd.read_csv("./IDL/out/EGP_hour_v03.txt",
    #                   delimiter="\s+",
    #                   parse_dates={'time':[0,1,2,3]},
    #                   infer_datetime_format=True,
    #                   date_parser=mydf,
    #                   index_col=0)

    idl = idl.drop(columns=['DayOfYear'])\
             .replace(-999, np.nan)\
             .apply(pd.to_numeric, errors='coerce')\
             .dropna(how='all')\
             .rename(columns={'AirPressure(hPa)' : 'p',
                          'AirTemperature(C)' : 't_1',
                          'AirTemperatureHygroClip(C)' : 't_2',
                          'RelativeHumidity(%)' : 'rh_cor',
                          'SpecificHumidity(g/kg)' : 'rh_cor2',
                          'WindSpeed(m/s)' : 'wspd',
                          'WindDirection(d)' : 'wdir',
                          'SensibleHeatFlux(W/m2)' : 'shf',
                          'LatentHeatFlux(W/m2)' : 'lhf',
                          'ShortwaveRadiationDown(W/m2)': 'dsr',
                          'ShortwaveRadiationDown_Cor(W/m2)' : 'dsr_cor',
                          'ShortwaveRadiationUp(W/m2)' : 'usr',
                          'ShortwaveRadiationUp_Cor(W/m2)' : 'usr_cor',
                          'Albedo_theta<70d' : 'albedo',
                          'Albedo' : 'albedo',
                          'LongwaveRadiationDown(W/m2)' : 'dlr',
                          'LongwaveRadiationUp(W/m2)' : 'ulr',
                          'CloudCover' : 'cc',
                          'SurfaceTemperature(C)' : 't_surf',
                          'HeightSensorBoom(m)' : 'z_boom',
                          'HeightStakes(m)': 'z_stake',
                          'DepthPressureTransducer(m)' : 'z_pt',
                          'DepthPressureTransducer_Cor(m)' : 'z_pt_cor',
                          'IceTemperature1(C)' : 't_i_1',
                          'IceTemperature2(C)' : 't_i_2',
                          'IceTemperature3(C)' : 't_i_3',
                          'IceTemperature4(C)' : 't_i_4',
                          'IceTemperature5(C)' : 't_i_5',
                          'IceTemperature6(C)' : 't_i_6',
                          'IceTemperature7(C)' : 't_i_7',
                          'IceTemperature8(C)' : 't_i_8',
                          'TiltToEast(d)' : 'tilt_x',
                          'TiltToNorth(d)' : 'tilt_y',
                          'TimeGPS(hhmmssUTC)' : 'gps_t',
                          'LatitudeGPS(degN)' : 'gps_lat',
                          'LongitudeGPS(degW)' : 'gps_lon',
                          'ElevationGPS(m)' : 'gps_alt',
                          'HorDilOfPrecGPS' : 'gps_hdop',
                          'LoggerTemperature(C)' : 't_logger',
                          'FanCurrent(mA)' : 'fan_dc',
                          'BatteryVoltage(V)' : 'batt_v'})

if 'df' not in locals():
    # df = xr.open_mfdataset("./data/L3/EGP/EGP-*_hour.nc", mask_and_scale=False)\
        #        .to_dataframe()

    # df = pd.read_csv("./data/L3/"+station+"/"+station+"-raw.csv", index_col=0, parse_dates=True)
    # df = pd.read_csv("./data/L3/"+station+"/"+station+"-STM.csv", index_col=0, parse_dates=True)
    # df = pd.read_csv("./data/L3/"+station+"/"+station+"-TX.csv", index_col=0, parse_dates=True)


    df = pd.read_csv("./test_QAS/L3/"+station+"/"+station+"-TX_hour.csv",
                      delimiter="\s+",
                      parse_dates={'time':[0,1,2,3,4]},
                      infer_datetime_format=True,
                      date_parser=mydf2,
                      index_col=0)
    
    df = df.drop(columns=['DayOfYear'])\
             .replace(-999, np.nan)\
             .apply(pd.to_numeric, errors='coerce')\
             .dropna(how='all')\
             .rename(columns={'AirPressure(hPa)' : 'p',
                          'AirTemperature(C)' : 't_1',
                          'AirTemperatureHygroClip(C)' : 't_2',
                          'RelativeHumidity(%)' : 'rh_cor',
                          'SpecificHumidity(g/kg)' : 'rh_cor2',
                          'WindSpeed(m/s)' : 'wspd',
                          'WindDirection(d)' : 'wdir',
                          'SensibleHeatFlux(W/m2)' : 'shf',
                          'LatentHeatFlux(W/m2)' : 'lhf',
                          'ShortwaveRadiationDown(W/m2)': 'dsr',
                          'ShortwaveRadiationDown_Cor(W/m2)' : 'dsr_cor',
                          'ShortwaveRadiationUp(W/m2)' : 'usr',
                          'ShortwaveRadiationUp_Cor(W/m2)' : 'usr_cor',
                          'Albedo_theta<70d' : 'albedo',
                          'Albedo' : 'albedo',
                          'LongwaveRadiationDown(W/m2)' : 'dlr',
                          'LongwaveRadiationUp(W/m2)' : 'ulr',
                          'CloudCover' : 'cc',
                          'SurfaceTemperature(C)' : 't_surf',
                          'HeightSensorBoom(m)' : 'z_boom',
                          'HeightStakes(m)': 'z_stake',
                          'DepthPressureTransducer(m)' : 'z_pt',
                          'DepthPressureTransducer_Cor(m)' : 'z_pt_cor',
                          'IceTemperature1(C)' : 't_i_1',
                          'IceTemperature2(C)' : 't_i_2',
                          'IceTemperature3(C)' : 't_i_3',
                          'IceTemperature4(C)' : 't_i_4',
                          'IceTemperature5(C)' : 't_i_5',
                          'IceTemperature6(C)' : 't_i_6',
                          'IceTemperature7(C)' : 't_i_7',
                          'IceTemperature8(C)' : 't_i_8',
                          'TiltToEast(d)' : 'tilt_x',
                          'TiltToNorth(d)' : 'tilt_y',
                          'TimeGPS(hhmmssUTC)' : 'gps_t',
                          'LatitudeGPS(degN)' : 'gps_lat',
                          'LongitudeGPS(degW)' : 'gps_lon',
                          'ElevationGPS(m)' : 'gps_alt',
                          'HorDilOfPrecGPS' : 'gps_hdop',
                          'LoggerTemperature(C)' : 't_logger',
                          'FanCurrent(mA)' : 'fan_dc',
                          'BatteryVoltage(V)' : 'batt_v'})


    
    # subset to same columns
    subset = np.intersect1d(df.columns, idl.columns)
    df = df[subset]
    idl = idl[subset]

    err = df - idl # need to understand data to understand error
    err_pct = err / idl.mean(axis='rows')*100 # % err but should work as long as mean != 0
    # err = (df - idl) / idl*100 # % err: large errors when values near 0
    # err = (df - idl) / idl.mean(axis='rows')*100 # % err but should work as long as mean != 0

    pd.options.display.float_format = "{:,.5f}".format

    err_desc = err.describe().T.drop(columns="count")
    err_pct_desc = err_pct.describe().T.drop(columns="count")

# diff_pct.plot()
# diff_pct.replace(0,np.nan).dropna(how='all', axis='columns').plot()
def plot_diff(df,idl,err,err_pct,var):
    import matplotlib.pyplot as plt
    fig = plt.figure(1)
    fig.clf()
    ax1 = fig.add_subplot(211)
    err[var].plot(label='err', color='red', marker='.', ax=ax1)
    ax1.set_ylabel("Err [units]")
    ax1_pct = ax1.twinx()
    err_pct[var].plot(label='err', color='black', marker='.', ax=ax1_pct)
    ax1_pct.set_ylabel("Err [%]")
    
    ax2 = fig.add_subplot(212, sharex=ax1)
    idl[var].plot(label='IDL '+var, linewidth=3, ax=ax2, marker='.', markersize=4)
    df[var].plot(label='Py', ax=ax2, marker='.', markersize=2)
    ax2.set_ylabel(var + " [units]")
    # (df[var]*0).plot(color='k', linestyle='--', ax=ax2, alpha=0.25, label='', marker='.')
    legend()
    
var = 't_1'; plot_diff(df,idl,err,err_pct,var)

# err_desc
# err_pct_desc
desc = err_desc.round(3).astype("string")
desc = desc + " (" + err_pct_desc.replace(np.nan,0).round().astype(int).astype("string") + ")"
desc

# if __name__ == "__main__":
#     print(desc)
#+END_SRC


** Compare 2

#+BEGIN_SRC jupyter-python
import numpy as np
import pandas as pd
import xarray as xr

station='QAS_L'

# if 'idl' in locals(): del(idl)
if 'df' in locals(): del(df)

def mydf(y,m,d,h):
    return pd.to_datetime(y+'-'+m+'-'+d+':'+h, format='%Y-%m-%d:%H')

## HOUR
idl = pd.read_csv("./test_QAS/processed_data/"+station+"_hour_v03.txt",
                  delimiter="\s+",
                  parse_dates={'time':[0,1,2,3]},
                  infer_datetime_format=True,
                  date_parser=mydf,
                  index_col=0)

idl = idl.drop(columns=['DayOfYear'])\
         .replace(-999, np.nan)\
         .apply(pd.to_numeric, errors='coerce')\
         .dropna(how='all')\
         .rename(columns={'AirPressure(hPa)' : 'p',
                          'AirTemperature(C)' : 't_1',
                          'AirTemperatureHygroClip(C)' : 't_2',
                          'RelativeHumidity(%)' : 'rh_cor',
                          'SpecificHumidity(g/kg)' : 'rh_cor2',
                          'WindSpeed(m/s)' : 'wspd',
                          'WindDirection(d)' : 'wdir',
                          'SensibleHeatFlux(W/m2)' : 'shf',
                          'LatentHeatFlux(W/m2)' : 'lhf',
                          'ShortwaveRadiationDown(W/m2)': 'dsr',
                          'ShortwaveRadiationDown_Cor(W/m2)' : 'dsr_cor',
                          'ShortwaveRadiationUp(W/m2)' : 'usr',
                          'ShortwaveRadiationUp_Cor(W/m2)' : 'usr_cor',
                          'Albedo_theta<70d' : 'albedo',
                          'Albedo' : 'albedo',
                          'LongwaveRadiationDown(W/m2)' : 'dlr',
                          'LongwaveRadiationUp(W/m2)' : 'ulr',
                          'CloudCover' : 'cc',
                          'SurfaceTemperature(C)' : 't_surf',
                          'HeightSensorBoom(m)' : 'z_boom',
                          'HeightStakes(m)': 'z_stake',
                          'DepthPressureTransducer(m)' : 'z_pt',
                          'DepthPressureTransducer_Cor(m)' : 'z_pt_cor',
                          'IceTemperature1(C)' : 't_i_1',
                          'IceTemperature2(C)' : 't_i_2',
                          'IceTemperature3(C)' : 't_i_3',
                          'IceTemperature4(C)' : 't_i_4',
                          'IceTemperature5(C)' : 't_i_5',
                          'IceTemperature6(C)' : 't_i_6',
                          'IceTemperature7(C)' : 't_i_7',
                          'IceTemperature8(C)' : 't_i_8',
                          'TiltToEast(d)' : 'tilt_x',
                          'TiltToNorth(d)' : 'tilt_y',
                          'TimeGPS(hhmmssUTC)' : 'gps_t',
                          'LatitudeGPS(degN)' : 'gps_lat',
                          'LongitudeGPS(degW)' : 'gps_lon',
                          'ElevationGPS(m)' : 'gps_alt',
                          'HorDilOfPrecGPS' : 'gps_hdop',
                          'LoggerTemperature(C)' : 't_logger',
                          'FanCurrent(mA)' : 'fan_dc',
                          'BatteryVoltage(V)' : 'batt_v'})


    
df = pd.read_csv("./test_QAS/L3/"+station+"/"+station+"-TX_hour.csv",
                 index_col=0, parse_dates=True)


# subset to same columns
subset = np.intersect1d(df.columns, idl.columns)
df = df[subset]
idl = idl[subset]

df = df['2021-10-22':'2021-10-28']
idl = idl['2021-10-22':'2021-10-28']

err = df - idl # need to understand data to understand error
err_pct = (err / idl.mean(axis='rows'))*100 # % err but should work as long as mean != 0
# err = (df - idl) / idl*100 # % err: large errors when values near 0
# err = (df - idl) / idl.mean(axis='rows')*100 # % err but should work as long as mean != 0

pd.options.display.float_format = "{:,.5f}".format

err_desc = err.describe().T.drop(columns="count")
err_pct_desc = err_pct.describe().T.drop(columns="count")

# diff_pct.plot()
# diff_pct.replace(0,np.nan).dropna(how='all', axis='columns').plot()
def plot_diff(df,idl,err,err_pct,var):
    import matplotlib.pyplot as plt
    fig = plt.figure(1)
    fig.clf()
    ax1 = fig.add_subplot(211)
    err[var].plot(label='err', color='red', marker='.', ax=ax1, linewidth=2)
    ax1.set_ylim(ax1.get_ylim()[0]*1.3, ax1.get_ylim()[1])
    ax1.set_ylabel("Err [units]")
    ax1_pct = ax1.twinx()
    err_pct[var].plot(label='err', color='black', marker='.', ax=ax1_pct, linewidth=0.5)
    ax1_pct.set_ylabel("Err [%]")
    # ax1.spines['left'].set_color('red')
    ax1.tick_params(axis='y', colors='red')
    ax1.yaxis.label.set_color('red')
    ax1.title.set_color('red')
    
    ax2 = fig.add_subplot(212, sharex=ax1)
    idl[var].plot(label='IDL '+var, linewidth=3, ax=ax2, marker='.', markersize=4)
    df[var].plot(label='Py '+var, ax=ax2, marker='.', markersize=3)
    ax2.set_ylabel(var + " [units]")
    # (df[var]*0).plot(color='k', linestyle='--', ax=ax2, alpha=0.25, label='', marker='.')
    legend()
    
var = 'wspd'; plot_diff(df,idl,err,err_pct,var)

# # err_desc
# # err_pct_desc
desc = err_desc.round(3).astype("string")
desc = desc + " (" + err_pct_desc.replace(np.nan,0).round().astype(int).astype("string") + ")"
desc

if __name__ == "__main__":
    print(desc.drop(columns=['std']))

#+END_SRC

#+RESULTS:
#+begin_example
                  mean            min         25%         50%        75%          max
albedo            <NA>           <NA>        <NA>        <NA>       <NA>         <NA>
batt_v         0.0 (0)        0.0 (0)     0.0 (0)     0.0 (0)    0.0 (0)      0.0 (0)
cc          -0.001 (0)    -0.17 (-34)     0.0 (0)     0.0 (0)    0.0 (0)    0.18 (36)
dlr          0.092 (0)    -13.79 (-5)   -0.03 (0)     0.0 (0)   0.03 (0)    18.32 (7)
dsr         -0.084 (0)  -59.49 (-144)   -0.03 (0)     0.0 (0)   0.03 (0)  71.08 (172)
dsr_cor           <NA>           <NA>        <NA>        <NA>       <NA>         <NA>
fan_dc         0.0 (0)        0.0 (0)     0.0 (0)     0.0 (0)    0.0 (0)      0.0 (0)
gps_alt        0.0 (0)        0.0 (0)     0.0 (0)     0.0 (0)    0.0 (0)      0.0 (0)
gps_hdop       0.0 (0)        0.0 (0)     0.0 (0)     0.0 (0)    0.0 (0)      0.0 (0)
gps_lat     -0.001 (0)     -0.001 (0)  -0.001 (0)  -0.001 (0)   -0.0 (0)     -0.0 (0)
gps_lon        0.0 (0)        0.0 (0)     0.0 (0)     0.0 (0)    0.0 (0)    0.001 (0)
p           -0.024 (0)       -1.0 (0)     0.0 (0)     0.0 (0)    0.0 (0)      1.0 (0)
rh_cor      -0.109 (0)    -8.63 (-12)   -0.03 (0)     0.0 (0)   0.02 (0)    7.51 (11)
t_1        0.034 (-84)  -0.06 (-1843)     0.0 (0)     0.0 (0)    0.0 (0)   0.75 (147)
t_2       0.032 (-128)  -0.27 (-3164)     0.0 (0)     0.0 (0)    0.0 (0)  0.78 (1095)
t_i_1          0.0 (0)        0.0 (0)     0.0 (0)     0.0 (0)    0.0 (0)      0.0 (0)
t_i_2       -0.001 (1)      -0.01 (0)     0.0 (0)     0.0 (0)    0.0 (0)     0.0 (13)
t_i_3          0.0 (0)        0.0 (0)     0.0 (0)     0.0 (0)    0.0 (0)      0.0 (0)
t_i_4       -0.001 (2)    -0.01 (-16)     0.0 (0)     0.0 (0)    0.0 (0)    0.01 (16)
t_i_5          0.0 (0)        0.0 (0)     0.0 (0)     0.0 (0)    0.0 (0)      0.0 (0)
t_i_6          0.0 (0)        0.0 (0)     0.0 (0)     0.0 (0)    0.0 (0)      0.0 (0)
t_i_7          0.0 (0)        0.0 (0)     0.0 (0)     0.0 (0)    0.0 (0)      0.0 (0)
t_i_8          0.0 (0)        0.0 (0)     0.0 (0)     0.0 (0)    0.0 (0)      0.0 (0)
t_surf       0.008 (0)    -0.23 (-44)     0.0 (0)     0.0 (0)    0.0 (0)    0.87 (12)
tilt_x      -0.101 (3)      -0.72 (0)     0.0 (0)     0.0 (0)    0.0 (0)     0.0 (18)
tilt_y     -0.109 (-4)    -0.71 (-27)     0.0 (0)     0.0 (0)    0.0 (0)      0.0 (0)
ulr          0.079 (0)      -1.32 (0)   -0.03 (0)    0.01 (0)   0.03 (0)     4.37 (1)
usr        -0.147 (-1)  -24.83 (-243)   -0.03 (0)     0.0 (0)   0.02 (0)   15.7 (153)
usr_cor           <NA>           <NA>        <NA>        <NA>       <NA>         <NA>
wdir          5.54 (5)   -12.28 (-11)   -0.02 (0)     0.0 (0)   0.01 (0)  316.5 (289)
wspd       -0.032 (-1)    -1.39 (-37)     0.0 (0)     0.0 (0)    0.0 (0)    1.62 (44)
z_boom       0.002 (0)     -0.004 (0)    -0.0 (0)   0.003 (0)  0.003 (0)    0.005 (0)
z_pt        -0.001 (0)     -0.005 (0)  -0.005 (0)  -0.004 (0)  0.005 (0)    0.005 (0)
z_stake        0.0 (0)     -0.004 (0)     0.0 (0)     0.0 (0)  0.001 (0)    0.003 (0)
#+end_example
